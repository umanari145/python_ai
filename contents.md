## 参考
【キカガク流】人工知能・機械学習 脱ブラックボックス講座 - 初級編 -
【ゼロから始めるデータ分析】 ビジネスケースで学ぶPythonデータサイエンス入門
## 機械学習の分類
- 教師あり学習(入力xと出力y)　・・ここが一番わかりやすい
  - 回帰：数値の予測(ex 部屋の広さから家賃を分類)
  - 分類：カテゴリーの予測(ex 赤ワインor 白ワイン)
- 教師なし学習(入力x)
  - クラスタリング(グルーピング　マーケティングなど)
  - 次元削減(データ減らしたり)
- 強化学習(データがないorほとんどない)


## 単回帰分析

例：部屋の広さと家賃
y:出力変数
x:入力変数(広さ、距離)

### モデルの作成
- Step1 「モデル」を決める(広さと家賃)
  データに基づいて数式の定義を見つける直線?曲線?<br>
  点をplotして数式の定義を行う→ y^(ハット) = ax+bのような・・・<br>
  データの中心化を行うと計算が楽になる(平均値で引いてあげて、原点に持ってきてあげる)
- Step2 パラメータにとっての適切→「評価関数」を決める
  予想-実際の差分が小さいものを求める(y実際-y^予測)の２乗を使う(マイナスを考慮、微分しやすさ)
  →n件の差分の累乗が最小になるもの
- Step3 評価関数の最小化
　→最小二乗法での対応


### python環境構築
mac→anacondaだとバージョン競合などが起こる
win→anacondaでいけるっぽい

## モデリング

よくあるミス
- 基礎分析を怠った
- 全部のデータを使う 
- 過学習・・特定のパターンのみに有効なものを引っ張ってしまう

未知のデータも予測できる
- 既知と未知を分ける
- train(学習)とtest(評価)

## モデリング手順
- 1.説明変数を決め、データを準備
- 2.モデルの準備
- 3.モデルの作成
- 4.モデルを使い予測
- 5.モデルの評価

## 単回帰モデル
- 1つの目的変数を１つの説明変数のみでモデル化する方法(y=ax+b)
- モデル作成後のモデル評価の関数 https://qiita.com/monda00/items/a2ee8e0da51953c24da8
## 重回帰モデル
- 1つの目的変数を複数の説明変数でモデル化する方法(y=ax+by+cz・・・)
- 天気などカテゴリーデータのものは独立したカラムを使ってフラグ化する
- 重回帰したのに点数が悪化することもある・・・・

## 精度を上げるには・・・特徴量(説明変数)が鍵
- 特徴量を作る、特徴量を選ぶ ex 年齢層 数値をカテゴリーデータに置き換える
- 特徴量が多すぎると過学習のリスクがある
- 単変量解析、モデルベース選択、反復選択などが手法として挙げられる

